from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn import metrics 
from sklearn.svm import SVC 
from sklearn.metrics import classification_report,confusion_matrix 
from sklearn.metrics import accuracy_score, precision_score, recall_score 
import matplotlib.pyplot as plt 
import numpy as np 
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split 
data = load_iris()
data.target_names
data.feature_names
df = pd.DataFrame(data.data,columns=data.feature_names)
df
df['target'] = data.target
df
df.describe()
df0 = df[df.target == 0]
df1 = df[df.target == 1]
df2 = df[df.target == 2]
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.scatter(df0['sepal length (cm)'], df0['sepal width (cm)'],color="green",marker='+' , label = data.target_names[0])
plt.scatter(df1['sepal length (cm)'], df1['sepal width (cm)'],color="blue",marker='.',  label = data.target_names[1])
plt.scatter(df2['sepal length (cm)'], df2['sepal width (cm)'],color="red",marker='*',  label = data.target_names[2])
plt.legend()
plt.show()
plt.xlabel('Petal Length')
plt.ylabel('Petal Width')
plt.scatter(df0['petal length (cm)'], df0['petal width (cm)'],color="green",marker='+')
plt.scatter(df1['petal length (cm)'], df1['petal width (cm)'],color="blue",marker='.')
plt.scatter(df2['petal length (cm)'], df2['petal width (cm)'],color="red",marker='*')
X = data.data 
y = data.target 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=33, random_state=42)
svc_model = SVC()
svc_model.fit(X_train, y_train)
y_pred = svc_model.predict(X_test)
y_pred
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
support_vector_indices = svc_model.support_ 
num_support_vectors = len(support_vector_indices)
print("Support vector indices:", support_vector_indices)
print("Number of support vectors:", num_support_vectors)
cs=classification_report(y_test,y_pred)
cm=confusion_matrix(y_test,y_pred) 
print(cs) 
print(cm) 
svc_linear = SVC(kernel='linear') 
svc_poly = SVC(kernel='poly')
svc_rbf = SVC(kernel='rbf') 
svc_linear.fit(X_train, y_train) 
svc_poly.fit(X_train, y_train) 
svc_rbf.fit(X_train, y_train) 
 y_pred_linear = svc_linear.predict(X_test) 
y_pred_poly = svc_poly.predict(X_test) 
y_pred_rbf = svc_rbf.predict(X_test) 
accuracy_linear = accuracy_score(y_test, y_pred_linear) 
precision_linear = precision_score(y_test, y_pred_linear, average='weighted')
recall_linear = recall_score(y_test, y_pred_linear, average='weighted') 
 

accuracy_poly = accuracy_score(y_test, y_pred_poly) 
precision_poly = precision_score(y_test, y_pred_poly, average='weighted') 
recall_poly = recall_score(y_test, y_pred_poly, average='weighted') 
 
accuracy_rbf = accuracy_score(y_test, y_pred_rbf) 
precision_rbf = precision_score(y_test, y_pred_rbf, average='weighted') 
recall_rbf = recall_score(y_test, y_pred_rbf, average='weighted') 
print("Accuracy:", accuracy_linear) 
print("Precision:", precision_linear) 
print("Recall:", recall_linear) 
 
print("\nMetrics for Polynomial Kernel:") 
print("Accuracy:", accuracy_poly) 
print("Precision:", precision_poly) 
print("Recall:", recall_poly)
print("\nMetrics for RBF Kernel:") 
print("Accuracy:", accuracy_rbf)
print("Precision:", precision_rbf) 
print("Recall:", recall_rbf) 
